\section{Introduction} \label{sec:intro}
The para-virtualization technology~\cite{XEN-SOPS03,denali-paravirtualization} is able to defend against the attacks from the software within guest Virtual Machines (VMs), but it is not armed with efficient protection approach to prevent DMA attacks~\cite{disaggregation}. To fix this gap, Intel and AMD propose the I/O virtualization (AMD-Vi~\cite{amdvt} and Intel VT-d~\cite{intelvt}) technology, which introduces a new Input/Output Memory Management Unit (IOMMU) to restrict DMA accesses on the specific physical memory addresses. Thus, the hypervisor could leverage IOMMU to protect itself by setting its occupied memory regions inaccessible for all DMA accesses. It is true for the hypervisor in the full virtualization (e.g., Hardware Virtual Machines (HVMs) and Xen~\cite{XEN-SOPS03}), since the memory boundary between the hypervisor and guest VMs are clear and statically fixed.


If the hypervisor and the guest VMs work in full virtualization (e.g., Hardware Virtual Machines (HVMs) and Xen~\cite{XEN-SOPS03}), the above solution is clean and secure to defend against both software and DMA attacks from guest VMs. However, in paravirtualized environment, there are many security-critical data structures, like Global Descriptor Table (GDT) and page tables, that are inevitably used by both the hypervisor and the guest VM~\cite{A novel hardware assisted full virtualization technique?, I remeber one paper discussing about this}. In such situations, the adversary could launch DMA requests to illicitly modify those shared data structures to open the door for the malicious guest software to bypass the security restrictions set by the hypervisor.

%Highlight the problem, and emphasise the importance.
I/O devices generate interrupts to asynchronously communicate
to the CPU the completion of I/O operations. In virtualized settings,
each device interrupt triggers a costly exit [2, 9, 26], causing the
guest to be suspended and the host to be resumed, regardless of
whether or not the device is assigned.
%existing work
Many previous studies that aim to improve device I/O performance 
While our work is different since it 1) aim to improve I/O performance for all I/O peripheral devices.

%introduce our approach
Our approach rests on the observation that the high interrupt
rates experienced by a core running an I/O-intensive guest are
mostly generated by devices assigned to the guest.

This revolutionary trend also urges us to significantly reshape modern operating systems to keep up the pace. Unfortunately, the current designs and implementations of modern operating systems lag behind the requirements.
In this paper, we focus on the improvement of I/O performance. Specifically, we aim to adopt guest OS kernel to further improve the I/O performance of all peripheral devices without sacrificing the security of the paravirtualized platforms. By deeply analyzing modern Xen hypervisor and Linux kernel, we surprisingly notice that the page table updates of guest OS could cause IOMMU to flush IOTLB. These flushes are necessary for the sake of the security of Xen hypervisor, but it inevitably increases the miss rate of IOTLB, and consequently reduces I/O performance, especially for the high-speed devices. Note that we are the first one to uncover this dependence between the security of paravirtualized (Xen) hypervisor and I/O performance. Based on this observation, we propose a novel algorithm that decreases the miss rate of IOTLB by carefully managing the guest page table updates, as well as retaining the security of paravirtualized hypervisor.
We implement our algorithm with no modification of Xen and small customizations of Linux kernel version 3.2.0 by only adding xxx SLoC, and evaluate the I/O performance in micro and macro ways. The micro experiment results indicate that the new algorithm is able to effectively reduce the miss rate of IOTLB, especially when the page tables are frequently updated. The macro benchmarks shows that the I/O devices always produce better (or the same) performance, especially when the system frequently generate many temporal processes.


%In particular, we make the following contributions:
%\begin{enumerate}
%\item We design \name which directly works on the application binary to prevent the all forms of ROP attacks with low performance overhead. Our technique requires no side information or binary rewriting.
%\item We implement \name on Linux platforms and similar implementation is compatible with the commodity operating system and all legacy applications.
%\item We evaluated the performance and security of our system. The experiment results show that \name is able to detect all ROP payloads without false positive and false negative.
%\end{enumerate}

The rest of the paper is structured as follows: In Section~\ref{sec:preli} and Section~\ref{sec:prob}, we briefly describe the background knowledge, and highlight our goal and the thread model. In Section~\ref{sec:rationale} we discuss the design rationale. Then we describe the system overview and implementation in Section~\ref{sec:overview} and Section~\ref{sec:implement}. In Section~\ref{sec:eva}, we evaluate the security and performance of the system, and discuss several attacks and possible extension in Section~\ref{sec:dis}. At last, we discuss the related work in Section~\ref{sec:related}, and conclude the whole paper in Section~\ref{sec:con}.

