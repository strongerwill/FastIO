\section{Introduction} \label{sec:intro}
The para-virtualization technology~\cite{XEN-SOPS03,denali-paravirtualization} is able to defend against the attacks from the software within guest Virtual Machines (VMs), but it is not armed with efficient protection approach to prevent DMA attacks~\cite{disaggregation}. 
To fix this gap, Intel and AMD propose the I/O virtualization (AMD-Vi~\cite{amdvt} and Intel VT-d~\cite{intelvt}) technology, which introduces a new Input/Output Memory Management Unit (IOMMU) to restrict DMA accesses on the specific physical memory addresses. 
Besides protecting the memory regions occupied by itself, the hypervisor also need to protect certain security-critical data strctures, like page tables, which are shared by the hypervisor and the guest VMs.


Intuitiviely, the hypervisor could leverage IOMMU to protect itself by setting its occupied memory regions inaccessible for all DMA accesses. 
However, it is not true for the paravirtualized hypervisors (e.g., Xen). 
In fact, in paravirtualized environment, there are many security-critical data structures, like Global Descriptor Table (GDT) and page tables, shared by both hypervisor and guest VMs~\cite{xxx}. 
In such situations, only protecting the hypervisor's memory regions is far enough, as the adversary could launch DMA requests to illicitly modify those shared data structures (e.g., page tables). 
Once these security restrictions are broken, the malicious VM's software would be able to levearge these vulnerabilities to compromise the hypervisor.


%Highlight the problem, and emphasise the importance.
I/O devices generate interrupts to asynchronously communicate
to the CPU the completion of I/O operations. In virtualized settings,
each device interrupt triggers a costly exit [2, 9, 26], causing the
guest to be suspended and the host to be resumed, regardless of
whether or not the device is assigned.
%existing work
Many previous studies that aim to improve device I/O performance
While our work is different since it 1) aim to improve I/O performance for all I/O peripheral devices.

%introduce our approach
Our approach rests on the observation that the high interrupt
rates experienced by a core running an I/O-intensive guest are
mostly generated by devices assigned to the guest.

This revolutionary trend also urges us to significantly reshape modern operating systems to keep up the pace. Unfortunately, the current designs and implementations of modern operating systems lag behind the requirements.
In this paper, we focus on the improvement of I/O performance. Specifically, we aim to adopt guest OS kernel to further improve the I/O performance of all peripheral devices without sacrificing the security of the paravirtualized platforms. By deeply analyzing modern Xen hypervisor and Linux kernel, we surprisingly notice that the page table updates of guest OS could cause IOMMU to flush IOTLB. These flushes are necessary for the sake of the security of Xen hypervisor, but it inevitably increases the miss rate of IOTLB, and consequently reduces I/O performance, especially for the high-speed devices. Note that we are the first one to uncover this dependence between the security of paravirtualized (Xen) hypervisor and I/O performance. Based on this observation, we propose a novel algorithm that decreases the miss rate of IOTLB by carefully managing the guest page table updates, as well as retaining the security of paravirtualized hypervisor.
We implement our algorithm with no modification of Xen and small customizations of Linux kernel version 3.2.0 by only adding xxx SLoC, and evaluate the I/O performance in micro and macro ways. The micro experiment results indicate that the new algorithm is able to effectively reduce the miss rate of IOTLB, especially when the page tables are frequently updated. The macro benchmarks shows that the I/O devices always produce better (or the same) performance, especially when the system frequently generate many temporal processes.


%In particular, we make the following contributions:
%\begin{enumerate}
%\item We design \name which directly works on the application binary to prevent the all forms of ROP attacks with low performance overhead. Our technique requires no side information or binary rewriting.
%\item We implement \name on Linux platforms and similar implementation is compatible with the commodity operating system and all legacy applications.
%\item We evaluated the performance and security of our system. The experiment results show that \name is able to detect all ROP payloads without false positive and false negative.
%\end{enumerate}

The rest of the paper is structured as follows: In Section~\ref{sec:preli} and Section~\ref{sec:prob}, we briefly describe the background knowledge, and highlight our goal and the thread model. In Section~\ref{sec:rationale} we discuss the design rationale. Then we describe the system overview and implementation in Section~\ref{sec:overview} and Section~\ref{sec:implement}. In Section~\ref{sec:eva}, we evaluate the security and performance of the system, and discuss several attacks and possible extension in Section~\ref{sec:dis}. At last, we discuss the related work in Section~\ref{sec:related}, and conclude the whole paper in Section~\ref{sec:con}. 
