\section{\name Overview} \label{sec:overview}
\begin{figure*}[ht]
\centering
\includegraphics[width=0.8\textwidth]{image/overview/arch.pdf} \\
\caption{\name Architecture. The semi-writable pages are managed by the \name cache, and all page type updates are validated by the \name module.
Through the cooperation of \name cache and \name module, \name successfully shortens the execution path of the guest page table (de)allocation and eliminates additional IOTLB flashes.}
\label{fig:arch}
\end{figure*}

\subsection{Requirements}\label{sec:req}
Before we describe the design overview, We'd like to share the requirements we considered in the design.
We summarize the requirements as follows, in terms of compatibility, development cost and security.
\begin{enumerate}
\item (R1) Unaltered system security. The new scheme should not sacrifice the system security to obtain benefits from I/O performance. No one likes to use a system with known design loopholes.
\item (R2) Compatible with legacy applications. The new scheme should limit the modifications on the guest kernel and the hypervisor, without any modifications on the existing applications.
\item (R3) Small modifications. The new scheme should minimize the development cost on the guest kernel and the hypervisor.
\item (R4) Minimizing additional IOTLB flushes. The new scheme should minimize the number of IOTLB flushes, such as reducing the number to zero.
\end{enumerate}

\subsection{\name Architecture}
Figure~\ref{fig:arch} depicts the architecture of \name. It consists of a \cache in the guest kernel and a \name module in the hypervisor space. 
%The \name kernel module enforces the protection on the selected application.
In the initial phase, the \cache allocates several pages from writable pages, converts them into semi-writable pages, and maintains them in a dedicated cache list.
When the guest kernel needs the page-table pages, the \cache pops out the semi-writable pages and asks the \module to.
 manages the page type updates between semi-writable page and page-table pages.
The \cache
The \name module enforces the fine-grained validation scheme on the page table pages.

%The \name kernel module is installed and executed before any user applications, and starts to enforce XnR property on the selected applications by manipulating the configurations of their page tables, e.g., clear the present bit in page table entries (PTEs) to set code pages non-readable.
%Thus, any data loads/store accesses on the code pages of the protected application are rejected.
%To allow the legal instruction fetch requires from the processor, the \name kernel module will temporally set back the present bit.
%The success of one instruction fetch will trigger the processor to cache the PTE entry in the iTLB, facilitating the following instruction fetch requests on this code page. Note that the iTLB only allows instruction fetches, rather than the data loads/stores, which rely on the dTLBs.
%To prevent the protected process from reading this code page, the \name kernel module will revert the change in an atomic way immediately after the success of the first instruction fetch.

\subsection{\name Cache}
The basic idea behind the \cache is to have caches of semi-writable pages kept in an initialized state available for use as page table pages by the kernel. 
Without the page oriented \cache, the kernel will spend much of its time allocating, initializing and freeing page-table pages. 
The slab allocator that is similar to the \cache cannot be used in our settings, due to the following reasons.
First, it violates the security requirements of page-table pages enforced by the hypervisor due to the type count.
In particular, the type count should be zero when a page is updated between writable page and page-table page.
However, the pages in the slab allocator are not always satisfy this restriction.
Second, it does not distinguish the page-table page with other pages that have the same size.
\yueqiang{interface issue, and size-oriented management}
At last, adding the fine-grained validation mechanism only for one object (i.e., page-table page) will subvert its generality of the slab allocator.
Considering the above three reasons, we give up customizing the existing slab allocator and aim to create a dedicated, called \cache, for page table allocation and deallocation.

\subsubsection{Cache Creation and Destruction}


\subsubsection{Cache Shrinking}
The \name cache does not automatically shrink itself.
When the memory management daemon (e.g., \emph{kswapd}) notices that memory is tight, it will explicitly call the exported interface of the \cache to free some memory.
%talk about the interface
The interfaces support to release pages by numbers or by percentage. 
For instance, the 
%the size of the cache.
In fact, the number of pages maintained in the \cache is not too much. In our experiments, it is always less than $180$, meaning the size of the cache is less than $720KB$.
Adding some meta data, the total size is always under $1MB$. 
Thus, in the almost 

\subsection{Fine-Grained Validation Mechanism}

It is challenging to reduce the number of the IOTLB flushes, as well as achieving all above requirements.
A possible approach is to let the hypervisor to manage the page table in its own space.
In this way, there is no need for flushing IOTLB, but it will dramatically increase the size of the hypervisor, and consequently reduce the system security level.
Another possible approach is to do the IOTLB flushing in a batch, meaning flushing multiple IOTLB entries all in one, instead of flushing them one after another.
This approach is able to retain the system security, but it could not eliminate the IOTLB flushes, only reducing the number of IOTLB flushes in a certain level.
\yueqiang{In addition, this approach may lead to security gap in a short time.}

In this paper, we attempt to solve this problem in a smart way, which could reduce the number of IOTLB flush to zero with only small modifications of the guest kernel and the hypervisor,
as well as retaining the system security.
In general, our approach is proposing a fine-grained security validation to replace the old and coarse-grained one doing page-table and DMA validation together.
Specifically, we observe that the original coarse-grained access control is the all-or-nothing style. i.e., the writable page is simultaneously writable for both software and DMA (device) while all other page types are non-writable for both software and DMA.
%In short, there ere only two types of pages: 1) \emph{writable page} and 2) \emph{non-writable page} (including three page-table page types and two segment descriptor page types), and their access permissions are mutually exclusive from each other.
%Thus, the page-type changing between them inevitably triggers the additional IOTLB flushes, otherwise there will be a security loophole.
To address this conflict without sacrificing the system security, we propose to create a new page type: \emph{semi-writable page}, which is writable for software but non-writable for DMA,
and require that the page type updates between the writable page and the page-table page must go through the semi-writable page first.
In practice,  we can further restrict that the system only updates the page-table pages to/from the semi-writable pages and holds the semi-writable pages to stop them converting back to the writable pages.
since both of them are already inaccessible to DMA, there is no need to do IOTLB flushes, meaning the additional IOTLB flushes could be totally avoided.
In order to facilitate the management of the semi-writable pages, we propose a new data structure (i.e., page table cache) in the guest kernel, and extend the existing page-management data structure in the hypervisor space.         l
Similar to the management of the page-table pages, the hypervisor is only responsible for the final validation of the semi-writable page, leaving all other management operations for the guest OS.
By doing this, we can keep the modifications as small as possible by reusing existing validation process and page-table management subsystem, and also retain the system security.


\eat{
\subsubsection{Fine grained access control}
%firstly, talk about how to reduce the IOTLB flush.
As revealed in previous sections, access control to writable pages is at a coarse granularity. Xen allows write-access both for guest OS and assigned I/O devices. Instead, \name caches a certain number of writable pages, prohibits DMA access for the cached writable pages while OS still has its write-permission. If they are updated to be page tables, Xen only limits OS to read-only permission (software protection) without modifying I/O page tables as well as IOTLB. Specifically, Xen maintains a new flag called \textbf{cache} with a machine page (a cached page), indicating that the corresponding page is cached by guest OS and free from DMA-access. Whatever page type a machine page is, if it owns the flag, Xen neither maps nor unmaps it from I/O page tables, thus avoiding an IOTLB-flush. Note that \name only considers page type updates between writable and page-table.

For instance, if guest OS creates a new page-table, Xen firstly reuses the validation process to enforce software protection, and then checks if the page has the \textbf{cache} flag. If so, the only thing that Xen needs to do is to update the page to be a page-table. If not, Xen sets the page with the new flag, clears \emph{read} and \emph{write} permission fields in I/O page tables and flushes IOTLB. As for the guest page table destruction, Xen also reuses existing security checks to remove software protection while maintains DMA prevention, after which the corresponding page is (if without the flag) set with the \textbf{cache} flag and updated to be writable. Figure \ref{fig:semi-type} describes the process.

\begin{figure}[ht]
\centering
\includegraphics[width=0.5\textwidth]{image/overview/page-type-updates-with-semi-type.png} \\
\caption{Page Type Updates between writable and page-table are through Semi-Writable}
\label{fig:semi-type}
\end{figure}

As can be seen in Figure \ref{fig:cache-flag}, every time page type updates between writable and page-table occur, every related page will own the flag, inaccessible to devices and all Xen needs to is to validate guest OS, having protected guest page tables and improved IOTLB performance, which satisfies R1,2.

As writable pages with \textbf{cache} flag freed by guest OS cannot be mixed with ordinary pages in the buddy system, \name builds up cache pools to manage freed writable pages in the OS space to function properly and serve as caches of page tables.

\subsection{Cache Mechanism}
%secondly, design the cache pool to support it
If guest OS directly frees pages with cache flag to the buddy system, which may allocate them for DMA transactions. This will lead to unacceptable access faults. As a result, \name enables OS to cache the writable pages for page-tables. Specifically, \name defines new cache allocating and freeing functions for every level of page table to manage cache and whichever existing page-table function will invoke the corresponding cache function. By this approach, \name reserves page-table caches. When dealing with process creation/destruction, OS allocates pages from or frees them into the cache pool instead of the buddy system, reducing time cost, thus meeting R2.

Cache mechanism begins its life-cycle either automatically with system booting up or dynamically during system runtime. \name provides an interface for users to activate dynamically. Utilizing the feature, users can improve system performance in an on-demand way (e.g., too many process-creation at some time). Basically, if the mechanism is activated dynamically, there may exists a few writable pages without cache flag and this does not ruin the security while flush IOTLB only once. Also note that when every cache pool is empty initially or OS asks for more pages (e.g., many processes creations) than cache pool could supply, cache allocating function always requests pages from the buddy system, which also affect IOTLB once.

During the runtime of the cache, \name also needs to control the memory size that caches take up. If the cache size becomes larger, it is necessary for cache freeing function to free pages from the pool into the buddy system. When to free pages in pool depends on two factors, namely $1$) a proportion between pages in use and in pool, and $2$) a total number of pages in use and in pool. If both factors exceed specific thresholds, respectively, corresponding cache flags must be cleared before the pages are freed. Thus, \name defines a new hypercall for OS. When handling the hypercall, Xen mainly clears the flag of specified pages, maps freed pages in the I/O page tables and flushes IOTLB. It can be concluded that inappropriate thresholds will lead to the flushes of IOTLB. Because of that, \name offers an interface for users to modify the default values of both thresholds in order to reduce IOTLB-flush or adjust cache size (meets R2). The default thresholds are determined by conducting experiments where no pages are freed to the buddy system (see details in section~\ref{sec:eva}), and the page number to free is stated in the equation below: $\Delta$num\_to\_free $=$ num\_in\_pool $-$ num\_in\_use. If users have only a few available memory in extreme cases, they are provided with another interface to manually free all pages in cache into the buddy system, thus relieving system's pressure while badly affecting IOTLB. Using the two interfaces, users have full control of the page-table cache.

This is the life-cycle of a cached page, originating from the buddy system, freed into the cache, then maybe allocated by the cache and finally freed into the buddy system when necessary.

Section~\ref{sec:implementation} will demonstrate its small modifications in details.

\zhi{But what if the memory percentage is too high? it is necessary to free pages from the cache pool to the buddy system. Pages in pool will be freed if $1$) a proportion between pages in use and in pool, and $2$) a total number of pages in use and in pool are greater. And data from group of cache-pre-enabled by default is referred to quantify the proportion and the total number. Actually, users can modify the two factors to adjust the cache pool size through an interface. 
On top of that, page number beyond the proportion is freed, stated in an equation below: $\Delta$num\_to\_free $=$ num\_in\_pool $-$ num\_in\_use. Since pre-enabling the cache is not flexible enough, we also provide another interface for users to activate the cache mechanism in an on-demand way. Users may make use of this feature to better improve system performance dynamically.} 


}