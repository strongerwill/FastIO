\section{Introduction} \label{sec:intro}
In paravirtualization~\cite{XEN-SOSP03,denali-paravirtualization}, the kernel of each guest Virtual Machine (VM) and the hypervisor share the same virtual space and many security-critical data structures, like page tables and Global Descriptor Table (GDT). All these data structures are manageed by the guest VM, but their updates will be intercepted and validated by the hypervisor~\cite{XEN-SOSP03} with the purporse of preventing malicious accesses from the guest software.
However, the paravirtualization technology itself is not armed with efficient protection to prevent DMA attacks~\cite{disaggregation}.
To fix this gap, the hypervisor has to resort to the I/O virtualization (AMD-Vi~\cite{amdvt} or Intel VT-d~\cite{intelvt}) technology, which introduces a new Input/Output Memory Management Unit (IOMMU) to restrict DMA accesses on the physical memory addresses occupied by the hypervisor and the shared security-critical data structures. 
Leveraging the combination of the paravirtualization and I/O virtualization, the hypervisor prevent all malicious accesses from processor and hardware perpherial devices.

%Highlight the problem, and emphasise the importance.
\textbf{Problem.} Although the combination of the paravirtualization and I/O virtualization brings strong security protection, but it also lead to the side effects on I/O performance, particularly on IOTLB flushes. 
Specifically, we surperisingly find out that certian updates on the guest page tables that are supposed to only affects the memory access from CPU have impacts on  the address translation process of DMA access due to the additional IOTLB flushes. 
In addition, these kinds of updates are often triggered during the whole life cycle of a running system.
As a consequence, the IOTLB flushing events are frequently triggered, which inevitably affect the I/O performance of all peripheral I/O devices.

%existing work

%introduce our approach
This new depdency issue between guest page table and the DMA transferring urges us to reshape the design of the guest operating system and the hypervisor to minimize the effects on the I/O performance. 
Unfortunately, no one is aware this issue and also no existing work sloves this problem.
In this paper, we aim to uncover this issue, and propose a corresponding solution to 

Our approach rests on the observation that the high IOTLB flush rates experienced by a guest VM running 
are mainly generated by the creations and exits of page tables. 

In this paper, we focus on the improvement of I/O performance. Specifically, we aim to adopt guest OS kernel to further improve the I/O performance of all peripheral devices without sacrificing the security of the paravirtualized platforms. By deeply analyzing modern Xen hypervisor and Linux kernel, we surprisingly notice that the page table updates of guest OS could cause IOMMU to flush IOTLB. These flushes are necessary for the sake of the security of Xen hypervisor, but it inevitably increases the miss rate of IOTLB, and consequently reduces I/O performance, especially for the high-speed devices. Note that we are the first one to uncover this dependence between the security of paravirtualized (Xen) hypervisor and I/O performance. Based on this observation, we propose a novel algorithm that decreases the miss rate of IOTLB by carefully managing the guest page table updates, as well as retaining the security of paravirtualized hypervisor.
We implement our algorithm with no modification of Xen and small customizations of Linux kernel version 3.2.0 by only adding xxx SLoC, and evaluate the I/O performance in micro and macro ways. The micro experiment results indicate that the new algorithm is able to effectively reduce the miss rate of IOTLB, especially when the page tables are frequently updated. The macro benchmarks shows that the I/O devices always produce better (or the same) performance, especially when the system frequently generate many temporal processes.


In particular, we make the following contributions:
\begin{enumerate}
\item We are the first to identify the  
\item .
\item .
\end{enumerate}

The rest of the paper is structured as follows: In Section~\ref{sec:preli} and Section~\ref{sec:prob}, we briefly describe the background knowledge, and highlight our goal and the thread model. In Section~\ref{sec:rationale} we discuss the design rationale. Then we describe the system overview and implementation in Section~\ref{sec:overview} and Section~\ref{sec:implement}. In Section~\ref{sec:eva}, we evaluate the security and performance of the system, and discuss several attacks and possible extension in Section~\ref{sec:dis}. At last, we discuss the related work in Section~\ref{sec:related}, and conclude the whole paper in Section~\ref{sec:con}. 
