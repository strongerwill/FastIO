\section{\name Discussion} \label{sec:dis}
%\zhi{Macrobenchmark results of netperf do not reveal IOTLB's impacts on the DMA transactions.}
\subsection{IOTLB Impacts on I/O Performance}

We use netperf to evaluate the performance of network-intensive workloads. To overcome the adverse effect caused by real network jitter, we physically connect the tested machine directly to a tester machine by a network cable, and then the tester machine as a client measures the network throughput by sending a bulk of TCP packets to the tested machine being a server. Specifically, the client connects to the tested server by building a single TCP connection. Test type is TCP\_STREAM, sending buffer size is $16KB$ and the connection lasts $60$ seconds. On top of that, the TCP\_STREAM test of netperf is conducted for $30$ runs to obtain an average throughput. Throughput in the cache-dynamic-enabled group is $87.93 \times 10^6$ bits per second ($1 mbps = 10^6 bits per second$), 0.02\% more than that of the cache-disabled group, shown in figure\ref{tab:netperf}. The slight throughput improvement is possibly because that \name spends less CPU cycles executing netperf. Seemingly, benefits of IOTLB-flush eliminations have not been observed so far.

\begin{table}[!ht]
\footnotesize
\begin{center}
\begin{tabular}{|l|l|l|}
\hline
{\textbf{Throughput ($mbps$)}} & {\textbf{dynamic-enabled}} & {\textbf{disabled}}    \\ \hline
Average Throughput &  $87.927$ & $87.903$ \\ \hline
Range of Throughput & $87.880-88.010$ & $87.880-87.950$ \\ \hline
\end{tabular}
\end{center}
\caption{When the cache is enabled, the upper limit of the throughput range is improved by 0.06\% while the average throughput of 30 runs is improved by 0.02\%. }
\label{tab:netperf}
\end{table}

Actually, Nadav Amit~\cite{amit2012iommu} and Moshe Malka~\cite{malka2015riommu} demonstrate that the overhead causing by walking IOMMU page tables due to the IOTLB misses is negligible and cannot be observed to be a I/O performance bottleneck under normal circumstances such as the netperf benchmark. Specifically, the main bottleneck is induced by I/O interrupt process and the TCP/IP stack.

To eliminate the high latencies of both interrupt delay and TCP/IP stack, Nadav Amit proposes a pseudo pass-through mode of IOMMU and utilizes a high-speed I/O device (i.e., Intelâ€™s I/O Acceleration Technology~\cite{lauritzenintel}) to observe the execution time penalty as a result of IOTLB misses. While Moshe Malka makes use of ibverbs library~\cite{ibverbs evaluation,kerr2011dissecting} to measure the cost of an IOTLB miss.
Both studies aim to create high performance settings that reduce the DMA transactions to the magnitude of $\upmu$s so that IOTLB becomes the dominant factor.

\subsection{When to Free Pages in Cache}

As talked before, when to free pages in cache relies on both the memory size of the cache and the proportion between the cache size and page-table size. Default thresholds of the two factors are determined by a particular setting created by a specific stress tool. Therefore, both thresholds may not work in other settings. If the thresholds are not set appropriately, freeing pages will occur often, thus causing IOTLB flush. This is why we provide an interface for users to manually modify the default thresholds. Nevertheless, the optimum tradeoff between cache size and IOTLB-flush is not easy to reach only by the simple interface and we plan to propose a self-adaption algorithm in the future work. Basically, the algorithm has the properties as follows.
\begin{enumerate}
\item (P1) Memory usage of the cache is under control.
\item (P2) Frequency of IOTLB-flush will drop to a lowest level.
\item (P3) The frequency will reach the level as soon as possible.
\end{enumerate}

Firstly, a upper limit to the cache size is set based on the memory usage of a target application. Under the limit, the algorithm is trying to eliminate IOTLB-flush with a fewest cache usage. By scanning the the frequency of IOTLB-flush periodically, the algorithm will appropriately adjust the cache size based on both the memory pages in cache and in page tables residing in the target application.


%When users dynamically enable the cache for the application, the algorithm is also invoked to record the memory usage by scanning  and then determine the proportion between them. If IOTLB-flush occurs during the period, increase the cache size. If the cache exceeds a particular percentage of , it is not supposed to be any higher even if IOTLB still flushes.


