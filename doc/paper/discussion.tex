\section{Discussion}\label{sec:dis}
%\zhi{Macrobenchmark results of netperf do not reveal IOTLB's impacts on the DMA transactions.}

\subsection{IOTLB Misses}
According to IOMMU specification~\cite{intelvt, amdvt}, a typical IOMMU is able to provide three types of IOTLB invalidation schemes, i.e., global invalidation, domain-selective invalidation, page-selective invalidation, which differ in granularity.
Specifically, the global invalidation will always invalidate all IOTLB entries as a whole.
The domain-selective invalidation only invalidates the selected VM domain's IOTLBs, whose performance is a little better than the global invalidation.
The page-selective invalidation that only invalidate the corresponding IOTLB could achieve the best performance, comparing with the previous two schemes.

If the IOMMU is configured to do the global or domain-selective invalidation, an IOTLB flush produced by the DMA validations will invalidate all related IOTLB entries, inevitably resulting in IOTLB misses for all DMA address translations. However, if the IOMMU is working with the page-selective invalidation scheme, one IOTLB flush will only invalidate one IOTLB entry, which may not be used immediately. It means the current DMA request may not be affected, but its effects may result in the future DMA transfer.
%Currently, we do not evaluate the relationship between the IOTLB flushes and IOTLB misses in the page selective invalidation scheme, and we plan to put it into the future work.

\subsection{Threshold for \name Cache Shrinking}
Besides the end user could send command to explicitly shrink the \cache, the \cache itself could shrink itself according to the predefined threshold.
However, the threshold is likely to be different for different workload environments. 
Thus, we should adjust the threshold according to the specific workload feature.
An interesting solution is to upgrade the \cache to allow itself to be aware of the workload updates and adjust the threshold accordingly.
It is not that easy to propose the self-adaption algorithm as there are many factors affecting the workload in a real system.
Another practical solution is run a training tool in the guest kernel to calculate the number and the proportion of the needed semi-writable pages and the page table pages.
However, this approach requires the workload is relatively stable, otherwise the end user has to do the training over and over again.
Fortunately, if the workload is updated in a regular way and the update pattern is known to the end user, the end user could have a shell script that updates the threshold using the exported virtual file in a proper time.


%When users dynamically enable the cache for the application, the algorithm is also invoked to record the memory usage by scanning and then determine the proportion between them. If IOTLB-flush occurs during the period, increase the cache size. If the cache exceeds a particular percentage of , it is not supposed to be any higher even if IOTLB still flushes.

\subsection{\name Cache on the Bare-metal OS}
We believe the design of the \cache could benefit the page table allocations and deallocation on the bare-metal OSes that directly work on hardware.
The usage pattern of the page table pages in paravirtual environment is similar if not the same to the one on the bare-metal OS.
Based on this feature, the deallocated page table pages are likely to be used in the near future by a newly created processes.
By caching the deallocated page-table pages, the \cache could quickly response to the following allocation requests, without needing to invoke the system allocators every time.
In the future, we plan to port the \cache onto a bare-metal OS, such as Linux, and fully evaluate its benefits.
